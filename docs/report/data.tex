\chapter{Daten}
Im  folgenden Kapitel werden die im Laufe dieser Arbeit verwendeten Trainingsdaten und Text Corpora genauer beschrieben. Es wird erläutert woher die Daten stammen, welchen Zweck sie erfüllen und wie die einzelnen Datensätze aufgebaut sind.

\section{Art der Datensätze}
\subsection{Trainingsdaten}
Die Trainingsdaten, welche in dieser Arbeit verwendet wurden können in zwei Klassen unterteilt werden:

\begin{itemize}
	\item Die Daten, welche Annotationen mit den entsprechenden Sentiments bereits mitlieferern, im Folgenden \emph{Supervised} genannt.
	\item Die zweite Klasse beinhaltet Daten, welche keine Annotationen mitliefern. Bei diesen lässt sich der Sentiment der einzelen Datensätze über Eigenschaften des Textes ableiten. Als Beispiel kann hier zum Beispiel die Emoticon-Annotation aus \cite{deriu2016sentiment} erwähnt werden. Dabei wurde der Sentiment eines Tweets daraus abgeleitet ob positive oder negative Emoticon im Tweet vorhanden sind. Diese Art von Daten wird im Folgenden \emph{Unsupervised} genannt.
\end{itemize}

\subsubsection{Supervised}
In der Klasse der Supervised Datensätze befinden sich alle, welche bereits Annotationen zum Sentiment mitliefern. Die hier verwendeten Datensätze wurden von Cieliebak et al. \cite{cieliebak2013potential} zur Verfügung gestellt.\\

\begin{table*}\centering
	\ra{1.3}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{@{}lllcccccccl@{}}
			\toprule
			\multicolumn{9}{c}{Verteilung Sentiments}\\
			\cmidrule(r){7-9}
			& Name & Textart & Anzahl Texte & \specialcell{Durchschnittliche\\Länge} & \specialcell{Durchschnittliche\\Anzahl Wörter} & positiv & neutral & negativ & Referenz &\\ \midrule
			& JCR{\_}quotations & Zitate aus Reden & $1'290$ & $147.4$ & $33.4$ & $15.0\%$ & $66.9\%$ & $18.1\%$ & \cite{cieliebak2013potential}\\
			& MPQ{\_}news & Nachrichtentexte & $11'111$ & $123.5$ & $27.3$ & $14.4\%$ & $55.4\%$ & $30.1\%$ & \cite{cieliebak2013potential}\\
			& MPQ{\_}reviews & Filmbewertungen & $11'111$ & $123.0$ & $26.8$  & $14.4\%$ & $55.4\%$ & $30.1\%$ & \cite{cieliebak2013potential}\\
			& SEM{\_}headlines & Nachrichtenüberschriften & $1'250$ & $34.1$ & $7.1$ & $13.9\%$ & $61.1\%$ & $24.9\&$ & \cite{cieliebak2013potential}\\
			& SemEval{\_}tweets & Tweets & 12'039 & $89.3$ & $22.5$ & $38.5\%$ & $45.5\%$ & $15.0\%$ & \cite{SemEval:2016:task4}\\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption{Statistiken zu Supervised Datensätzen}
\end{table*}

\subsubsection{Unsupervised}
Für die Distant-Phase wurde ein Corpus von 82'000'000 Amazon Reviews verwendet, welche im Rahmen der Veröffentlichung von \cite{zhang2015character} öffentlich bereitgestellt wurden.

\subsection{Text Corpora}
Um die Word-Embeddings für die durchgeführten Experimente zu generieren wurden die unten beschriebenen Text Corpora verwendet.

\subsubsection{Tweets}
Für die Experimente, welche mit annotierten Tweets als Trainingsdaten durchgeführt wurden, wurden Word-Embeddings von Jan Deriu zur Verfügung gestellt. Diese Word-Embeddings wurden auf einem Corpus von 600'000'000 Tweets generiert.

\subsubsection{News}
Für die Experimente, welche mit annotierten Filmbewertungen durchgeführt wurden, wurden Word-Embeddings auf einem Corpus von englischen Nachrichten-Texten aus den Jahren 2007-2013 generiert. Diese wurden im Rahmen des neunten \emph{workshop on statistical machine translation} öffentlich zur Verfügung gestellt wurde\footnote{http://www.statmt.org/wmt14/training-monolingual-news-crawl/}. Der Corpus setzt sich aus 90'209'983 Nachrichtentexten und -überschriften zusammen, welche per Web-Crawling im Internet gesammelt wurden.