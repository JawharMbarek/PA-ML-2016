\chapter{Daten}
Im  folgenden Kapitel werden die im Laufe dieser Arbeit verwendeten Trainingsdaten und Text Corpora genauer beschrieben. Es wird erläutert woher die Daten stammen, welchen Zweck sie erfüllen und wie die einzelnen Datensätze aufgebaut sind. Des Weiteren wird erläutert wie die Word-Embeddings und Datensätze für die Distant-Supervised Phase generiert werden.

Die Trainingsdaten, welche in dieser Arbeit verwendet werden, können in zwei Klassen unterteilt werden:

\begin{itemize}
	\item \emph{Supervised}: Datensätze, welche Texte und dazugehörige Sentiments mitliefern werden gehören zur Klasse der Supervised Datensätze. Dazu zählen beispielsweise alle Trainings- und Testdaten welche in den Folgenden Experimente verwendet werden.
	\item \emph{Unsupervised}: Datensätze, welche Texte aber keine zugehörigen Sentiments mitliefern gehören zur Klasse der Unsupervised Datensäte. Dazu zählen einerseits die Daten, mit welchen die Distant-Supervised Phase durchgeführt wird. Andererseits gehören hierzu auch die Text-Corpora mit welchen die Word-Embeddings generiert werden.
\end{itemize}

\clearpage

\subsection{Supervised}
\label{data:supervised_data}
Alle Datensätze welche während des Trainings und der Evaluierung eines \gls{CNN} verwendet werden liefern Texte und die dazugehörigen Sentiments mit. Da die Datensätze nur als ganzes zur Verfügung stehen werden diese von uns im Verhältnis 80\% Trainingsdaten und 20\% Testdaten zufällig unterteilt.
\paragraph{Trainingsdaten} Die in der folgenden Tabelle aufgelisteten Datensätze werden für das Training der \gls{CNN}s verwendet.
\begin{table}[H]
	\ra{1.3}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{@{}lllcccccccl@{}}
			\toprule
			& & & & & & \multicolumn{3}{c}{Verteilung Sentiments} &\\
			\cmidrule(r){7-9}
			& Name & Textart & Anzahl Texte & \specialcell{Durchschnittliche\\Anzahl Zeichen} & \specialcell{Durchschnittliche\\Anzahl Wörter} & positiv & neutral & negativ & Quelle &\\ \midrule
			& DAI{\_}tweets & Tweets & $3274$ & $63.4$ & $16.1$ & $19.4\%$ & $66.9\%$ & $13.6\%$ & \cite{Narr:2012}\\
			& DIL{\_}reviews & Produktbewertungen & $3420$ & $74.0$ & $19.0$ & $31.1\%$ & $50.8\%$ & $17.9\%$ & \cite{Ding:2008}\\
			& HUL{\_}reviews & Produktbewertungen & $3156$ & $70.7$ & $18.6$ & $28.4\%$ & $57.7\%$ & $13.9\%$ & \cite{Hu:2004}\\
			& JCR{\_}quotations & Zitate aus Reden & $1032$ & $148.4$ & $33.6$ & $15.0\%$ & $71.3\%$ & $13.7\%$ & \cite{Balahur:2013}\\
			& MPQ{\_}news & Nachrichtentexte & $8888$ & $123.3$ & $26.9$ & $14.8\%$ & $55.5\%$ & $29.7\%$ & \cite{Wiebe:2005}\\
			& SEM{\_}headlines & Nachrichtenüberschriften & $1000$ & $34.3$ & $7.1$ & $14.4\%$ & $61.0\%$ & $24.6\%$ & \cite{Strapparava:2007}\\
			& SemEval{\_}tweets & Tweets & $8226$ & $89.1$ & $22.4$ & $37.2\%$ & $48.1\%$ & $14.7\%$ & \cite{SemEval:2016:task4}\\
			& TAC{\_}news & Nachrichtentexte & $2152$ & $88.6$ & $22.4$ & $36.3\%$ & $17.7\%$ & $46.0\%$ & \cite{Tackstrom:2011}\\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption{Statistiken zu Texten der Trainingsdaten.}
\end{table}

\paragraph{Testdaten} Die in der folgenden Tabelle aufgelisteten Datensätze werden verwendet um die Performanz eines trainierten \gls{CNN} zu evaluieren.
\begin{table}[H]
	\ra{1.3}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{@{}lllcccccccl@{}}
			\toprule
			& & & & & & \multicolumn{3}{c}{Verteilung Sentiments} &\\
			\cmidrule(r){7-9}
			& Name & Textart & Anzahl Texte & \specialcell{Durchschnittliche\\Anzahl Zeichen} & \specialcell{Durchschnittliche\\Anzahl Wörter} & positiv & neutral & negativ & Quelle &\\ \midrule
			& DAI{\_}tweets & Tweets & $819$ & $66.5$ & $16.8$ & $19.8\%$ & $67.9\%$ & $12.3\%$ & \cite{Narr:2012}\\
			& DIL{\_}reviews & Produktbewertungen & $855$ & $74.9$ & $19.2$ & $31.6\%$ & $51.6\%$ & $16.8\%$ & \cite{Ding:2008}\\
			& HUL{\_}reviews & Produktbewertungen & $789$ & $63.3$ & $17.1$ & $21.7\%$ & $53.3\%$ & $25.0\%$ & \cite{Hu:2004}\\
			& JCR{\_}quotations & Zitate aus Reden & $258$ & $143.6$ & $32.6$ & $14.7\%$ & $49.2\%$ & $36.1\%$ & \cite{Balahur:2013}\\
			& MPQ{\_}news & Nachrichtentexte & $2223$ & $121.6$ & $26.5$ & $13.1\%$ & $55.1\%$ & $31.8\%$ & \cite{Wiebe:2005}\\
			& SEM{\_}headlines & Nachrichtenüberschriften & $255$ & $33.4$ & $7.1$ & $12.0\%$ & $61.6\%$ & $26.4\%$ & \cite{Strapparava:2007}\\
			& SemEval{\_}tweets & Tweets & $3813$ & $89.6$ & $21.8$ & $41.2\%$ & $43.0\%$ & $15.8\%$ & \cite{SemEval:2016:task4}\\
			& TAC{\_}news & Nachrichtentexte & $537$ & $110.4$ & $26.7$ & $26.6\%$ & $12.1\%$ & $61.2\%$ & \cite{Tackstrom:2011}\\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption{Statistiken zu Texten der Testdaten.}
\end{table}

\clearpage

\subsection{Unsupervised}
Im Folgenden werden die \emph{Unsupervised} Datensätze erläutert. Einerseits beinhalten diese die Text-Corpora mit welchen die Word-Embeddings generiert werden, andererseits gehören hierzu auch die Datensätze welche für das Training der \gls{CNN}s während der Distant-Supervised Phasen eingesetzt werden.

\paragraph{Text-Corpora} Im Rahmen dieser Arbeit werden vier verschiedene Arten von Word-Embeddings verwendet. Diese werden auf verschiedenen Text-Corpora generiert, welche in der folgenden Tabelle aufgelistet sind:

\begin{table}[H]
	\centering
	\ra{1.3}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{@{}lllcccccccl@{}}
			\toprule
			Name & Beschreibung & Anzahl Sätze & Quelle\\ \midrule
			\emph{News} & News-Texte von diversen Webseiten & 90 Mio. & STATMT Webseite\tablefootnote{http://www.statmt.org/wmt14/training-monolingual-news-crawl/}\\
			\emph{Tweets} & Sammlung von öffentlich verfügbaren Tweets & 590 Mio. & Twitter-API\tablefootnote{https://dev.twitter.com/rest/public}\\
			\emph{Wiki} & Texte aller Artikel auf Wikipedia mit mehr als 50 Wörtern & 4.5 Mio. & Wikimedia\tablefootnote{https://dumps.wikimedia.org/enwiki/latest/}\\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption{Text-Corpora, welche für die Generierung der Word-Embeddings verwendet werden.}
\end{table}
Zusätzlich werden während der Experimente zufällig initialisierte Word-Embeddings verwendet; diese werden im Folgenden mit \emph{Random} gekennzeichnet. Die Generierung der Word-Embeddings wurde mittels \emph{word2vec} \cite{mikolov2013distributed} durchgeführt. Dabei wurden die folgenden Hyperparameter verwendet:

\begin{table}[H]
	\centering
	\ra{1.3}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{@{}lllcccccccl@{}}
			\toprule
			Name & Wert\\ \midrule
			\emph{algorithm} & skip-gram\\
			\emph{dimensions} & $52$\\
			\emph{window size} & $5$\\
			\emph{minimum count} & $15$\\
			\emph{sample} & $10^{-5}$\\
			\emph{hierarchical softmax} & \texttt{false}\tablefootnote{Bedeutet das \emph{negative sampling} verwendet wird.}\\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption{Hyperparameter, welche für die Generierung der Word-Embeddings mit \emph{word2vec} verwendet werden.}
\end{table}

\clearpage

\paragraph{Datensätze für Distant-Supervised Phase} Im Rahmen dieser Arbeit werden zwei verschiedene Datensätze für die Distant-Supervised Phase verwendet: Produktbewertungen von Amazon\footnote{https://www.amazon.com/} und Kurznachrichtentexte von Twitter\footnote{https://twitter.com/}. Dabei werden die Sentiments bei den Produktbewertungen anhand der vergebenen Wertung und bei den Tweets anhand der im Text vorhandenen Emoticons abgeleitet. Bei den Produktbewertungen werden alle Texte, welche mit einer Wertung von $x >= 4$ als positiv, $x < 3$ als negativ klassifiziert; die Restlichen werden als neutral angenommen. Bei den Tweets wird ein Lexikon von positiven (z.B. \quotes{:-)}) und negativen (z.B. \quotes{:-(}) Emoticons verwendet. Die Emoticons werden nach der Klassifizierung aus den Tweets entfernt.\\\\
Dieses Schema führt zu folgenden Datensätzen, welche während der Distant-Supervised Phase verwendet werden:
\begin{table}[H]
	\ra{1.3}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{@{}lllcccccccl@{}}
			\toprule
			& & & & & & \multicolumn{3}{c}{Verteilung Sentiments} &\\
			\cmidrule(r){7-9}
			& Name & Textart & Anzahl Texte & \specialcell{Durchschnittliche\\Anzahl Zeichen} & \specialcell{Durchschnittliche\\Anzahl Wörter} & positiv & neutral & negativ & Quelle &\\ \midrule
			& Amazon Reviews & Produktbewertungen & $82.4$ Mio. & $382.2$ & $96.2$ & $78.2\%$ & $8.5\%$ & $13.2\%$ & \cite{Zhang:2015}\\
			& Tweets & Tweets & $100.0$ Mio. & $46.9$ & $12.4$ & $79.1\%$ & $0.0\%$ & $20.9\%$ & Twitter-API\tablefootnote{https://dev.twitter.com/rest/public}\\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption{Statistiken zu Texten der Distant-Supervised Datensätze.}
\end{table}

Des Weiteren werden auch Experimente ohne Distant-Supervised Phase durchgeführt; diese werden mit \emph{None} gekennzeichnet.
